"""Compare live signal metrics against a historical baseline."""
from __future__ import annotations

import argparse
import json
import math
from pathlib import Path
from typing import Any, Sequence

import numpy as np
import pandas as pd

from src.monitoring.metrics import ks_statistic

DEFAULT_LOG_PATH = Path("artifacts/live/paper_trade_realtime.csv")
DEFAULT_BASELINE_PATH = Path("artifacts/analysis/live_baseline_summary.json")
DEFAULT_WINDOW = 240
DEFAULT_ALERT_THRESHOLD = 2.0
TABLE_HEADERS = (
    "metric",
    "recent_mean",
    "recent_std",
    "baseline_mean",
    "baseline_std",
    "z_score",
    "ks",
    "alert",
)


def parse_args(argv: Sequence[str] | None = None) -> argparse.Namespace:
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument(
        "--log-path",
        type=Path,
        default=DEFAULT_LOG_PATH,
        help="Path to the live signal CSV log.",
    )
    parser.add_argument(
        "--baseline-path",
        type=Path,
        default=DEFAULT_BASELINE_PATH,
        help="Path to the baseline JSON generated by build_signal_baseline.",
    )
    parser.add_argument(
        "--window",
        type=int,
        default=DEFAULT_WINDOW,
        help="Number of most recent rows to evaluate (default: 240).",
    )
    parser.add_argument(
        "--alert-threshold",
        type=float,
        default=DEFAULT_ALERT_THRESHOLD,
        help="Absolute z-score or KS value that triggers an alert (default: 2.0).",
    )
    parser.add_argument(
        "--output-format",
        choices=("table", "json"),
        default="table",
        help="Render results as an ASCII table or machine-readable JSON.",
    )
    parser.add_argument(
        "--output-json",
        type=Path,
        default=None,
        help="Optional path to persist the JSON summary when --output-format json is used.",
    )
    return parser.parse_args(argv)


def load_log(path: Path) -> pd.DataFrame:
    if not path.exists():
        raise FileNotFoundError(f"Log CSV not found: {path}")

    df = pd.read_csv(path)
    if df.empty:
        raise ValueError("Log CSV is empty.")

    if "ts" in df.columns:
        df["ts"] = pd.to_datetime(df["ts"], errors="coerce")
        df = df.sort_values("ts")

    return df


def load_baseline(path: Path) -> dict[str, Any]:
    if not path.exists():
        raise FileNotFoundError(f"Baseline JSON not found: {path}")

    try:
        return json.loads(path.read_text())
    except json.JSONDecodeError as exc:  # pragma: no cover - protects against malformed baseline
        raise ValueError(f"Baseline JSON is invalid: {path}") from exc


def take_window(df: pd.DataFrame, window: int) -> pd.DataFrame:
    if window <= 0:
        return df
    return df.tail(window)


def approximate_baseline_samples(stats: dict[str, Any], sample_size: int = 512) -> np.ndarray | None:
    quantiles = stats.get("quantiles")
    if not quantiles:
        return None

    q_points: list[float] = []
    v_points: list[float] = []

    min_val = stats.get("min")
    max_val = stats.get("max")
    if min_val is None or max_val is None:
        return None

    q_points.append(0.0)
    v_points.append(float(min_val))

    for key, value in sorted(quantiles.items(), key=lambda item: float(item[0])):
        try:
            q = float(key)
        except ValueError:
            continue
        q_points.append(q)
        v_points.append(float(value))

    q_points.append(1.0)
    v_points.append(float(max_val))

    if len(q_points) < 2:
        return None

    arr_p = np.linspace(0.0, 1.0, sample_size)
    return np.interp(arr_p, q_points, v_points)


def compute_metric_summary(
    metric: str,
    series: pd.Series,
    baseline_stats: dict[str, Any],
    alert_threshold: float,
) -> dict[str, Any]:
    series = series.dropna()
    count = int(series.count())
    summary: dict[str, Any] = {
        "count": count,
        "recent_mean": float(series.mean()) if count else math.nan,
        "recent_std": float(series.std(ddof=0)) if count else math.nan,
        "baseline_mean": baseline_stats.get("mean"),
        "baseline_std": baseline_stats.get("std"),
        "z_score": math.nan,
        "ks_statistic": math.nan,
        "alert": False,
    }

    baseline_mean = baseline_stats.get("mean")
    baseline_std = baseline_stats.get("std")
    if count and baseline_mean is not None and baseline_std is not None and baseline_std > 0:
        summary["z_score"] = (summary["recent_mean"] - float(baseline_mean)) / float(baseline_std)

    baseline_samples = approximate_baseline_samples(baseline_stats)
    if count > 1 and baseline_samples is not None and baseline_samples.size > 1:
        ks_value = ks_statistic(series.to_numpy(dtype=float), baseline_samples)
        summary["ks_statistic"] = ks_value

    z_val = summary["z_score"]
    ks_val = summary["ks_statistic"]
    if (isinstance(z_val, (float, int)) and not math.isnan(z_val) and abs(z_val) > alert_threshold) or (
        isinstance(ks_val, (float, int)) and not math.isnan(ks_val) and ks_val > alert_threshold
    ):
        summary["alert"] = True

    return summary


def build_summary(
    df_window: pd.DataFrame,
    baseline: dict[str, Any],
    alert_threshold: float,
) -> dict[str, Any]:
    baseline_columns = baseline.get("columns", {})
    summary: dict[str, Any] = {
        "window_size": int(df_window.shape[0]),
        "baseline_row_count": int(baseline.get("row_count", 0)),
        "alert_threshold": alert_threshold,
        "metrics": {},
        "alerts": [],
    }

    for metric, stats in baseline_columns.items():
        if not isinstance(stats, dict) or "error" in stats:
            summary["metrics"][metric] = {"error": "baseline_missing"}
            continue

        if metric not in df_window.columns:
            summary["metrics"][metric] = {"error": "missing_column"}
            continue

        metric_summary = compute_metric_summary(metric, df_window[metric], stats, alert_threshold)
        summary["metrics"][metric] = metric_summary
        if metric_summary.get("alert"):
            summary["alerts"].append(metric)

    return summary


def format_table(summary: dict[str, Any]) -> str:
    rows: list[tuple[str, ...]] = []
    for metric, stats in summary["metrics"].items():
        if "error" in stats:
            rows.append((metric, stats["error"], "", "", "", "", "", ""))
            continue

        rows.append(
            (
                metric,
                f"{stats['recent_mean']:.6f}" if not math.isnan(stats["recent_mean"]) else "nan",
                f"{stats['recent_std']:.6f}" if not math.isnan(stats["recent_std"]) else "nan",
                f"{float(stats['baseline_mean']):.6f}" if stats["baseline_mean"] is not None else "nan",
                f"{float(stats['baseline_std']):.6f}" if stats["baseline_std"] is not None else "nan",
                f"{stats['z_score']:.3f}" if not math.isnan(stats["z_score"]) else "nan",
                f"{stats['ks_statistic']:.3f}" if not math.isnan(stats["ks_statistic"]) else "nan",
                "ALERT" if stats["alert"] else "",
            )
        )

    widths = [len(header) for header in TABLE_HEADERS]
    for row in rows:
        for idx, cell in enumerate(row):
            widths[idx] = max(widths[idx], len(cell))

    header_line = " | ".join(header.ljust(widths[idx]) for idx, header in enumerate(TABLE_HEADERS))
    separator = "-+-".join("-" * widths[idx] for idx in range(len(TABLE_HEADERS)))
    body_lines = [" | ".join(cell.ljust(widths[idx]) for idx, cell in enumerate(row)) for row in rows]

    metadata = (
        f"window_size={summary['window_size']}, "
        f"baseline_rows={summary['baseline_row_count']}, "
        f"alert_threshold={summary['alert_threshold']}"
    )

    table = [metadata, header_line, separator, *body_lines]
    if summary["alerts"]:
        table.append(f"ALERTS: {', '.join(summary['alerts'])}")
    else:
        table.append("ALERTS: none")
    return "\n".join(table)


def maybe_write_json(output_path: Path | None, payload: dict[str, Any]) -> None:
    if not output_path:
        return
    output_path.parent.mkdir(parents=True, exist_ok=True)
    output_path.write_text(json.dumps(payload, indent=2))


def main(argv: Sequence[str] | None = None) -> int:
    args = parse_args(argv)

    df_log = load_log(args.log_path)
    df_window = take_window(df_log, args.window)
    baseline = load_baseline(args.baseline_path)

    summary = build_summary(df_window, baseline, args.alert_threshold)

    if args.output_format == "table":
        print(format_table(summary))
        print()
        print(json.dumps(summary, indent=2))
    else:
        json_payload = json.dumps(summary, indent=2)
        print(json_payload)
        maybe_write_json(args.output_json, summary)

    return 0


if __name__ == "__main__":
    raise SystemExit(main())
