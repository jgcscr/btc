# Experiment: BTCUSDT 1h Forecasting & Trading (2024-10-01 to 2025-12-10) – v1

## 1. Data Window & Coverage

- **Instrument**: BTCUSDT (Binance, spot and futures).
- **Interval**: 1h bars.
- **Curated table**: `jc-financial-466902.btc_forecast_curated.btc_features_1h`
- **Coverage (ts column)**:
  - `min_ts`: `2024-10-01 00:59:59`
  - `max_ts`: `2025-12-10 23:59:59`
  - `n_rows`: `~10,899` (1h bars; exact count may vary slightly if filters change)

Raw tables used to build the curated table:

- `jc-financial-466902.btc_forecast_raw.spot_klines`
- `jc-financial-466902.btc_forecast_raw.futures_metrics`

Both raw tables were fully backfilled over the same period using Parquet files stored in:

- `gs://jc-financial-466902-btc-forecast-data/spot_klines/interval=1h/...`
- `gs://jc-financial-466902-btc-forecast-data/futures_metrics/interval=1h/...`

The curated table `btc_features_1h` was rebuilt from these raw sources and verified to match the above coverage.

---

## 2. Labels & Targets

### Primary Target

- **Name**: `ret_1h`
- **Definition**: Backward 1h log return of the BTCUSDT close price:
  - $ \text{ret_1h}_t = \ln(\text{close}_t) - \ln(\text{close}_{t-1}) $

### Direction Target

- **Name**: binary direction label
- **Definition**: $ y^{(\text{dir})}_t = \mathbf{1}\{\text{ret_1h}_t > 0\} $ with threshold `0.0`.

### Forward Return (Not Used as Feature)

- **Name**: `ret_fwd_3h`
- **Definition**: 3-hour **forward** log return (used historically as an analysis column).
- **Important**: `ret_fwd_3h` is **never** included in the feature matrix `X` for any model; it is explicitly excluded in `src/data/dataset_preparation.py`.

---

## 3. Feature Set

Features are derived from the curated table `btc_features_1h`. The Python function `make_features_and_target` in `src/data/dataset_preparation.py`:

- Sorts rows by `ts`.
- Drops rows with `NaN` in the target column.
- Uses all remaining **numeric** columns as features **except**:
  - `ts`
  - The target column (e.g., `ret_1h`)
  - `ret_fwd_3h`

Resulting feature families include (non-exhaustive):

- **Spot OHLCV**:
  - `open`, `high`, `low`, `close`
  - `volume`, `quote_volume`, `num_trades`
- **Rolling & ratio features**:
  - `ma_close_7h`, `ma_close_24h`, `ma_ratio_7_24`
  - `vol_24h` and other rolling-volume measures
- **Futures metrics** (currently low/zero importance in this experiment):
  - `fut_open`, `fut_high`, `fut_low`, `fut_close`
  - `open_interest`, `funding_rate`, and related columns

No forward-looking targets such as `ret_fwd_3h` are used as features.

---

## 4. Split Logic

Splits are implemented in `time_series_train_val_test_split` in `src/data/dataset_preparation.py`:

- **Chronological ordering**:
  - Data are sorted by `ts` before splitting.
- **Fractions**:
  - Train: `train_frac = 0.70`
  - Validation: `val_frac = 0.15`
  - Test: `test_frac = 0.15` (remainder)
- **Index-based slicing**:
  - `X_train = X[:train_end]`
  - `X_val = X[train_end:val_end]`
  - `X_test = X[val_end:]`
- **Scaling**:
  - A `StandardScaler` is **fit on `X_train` only**.
  - The fitted scaler is then applied to `X_val` and `X_test`.
- **No shuffling**:
  - There is no random shuffling; all splits respect time ordering.

This ensures:

- No label leakage from test/validation into training via scaling.
- Splits align with a realistic forward-looking evaluation.

Datasets are stored as NPZ files:

- Regression: `artifacts/datasets/btc_features_1h_splits.npz`
- Direction: `artifacts/datasets/btc_features_1h_direction_splits.npz` (for training the direction model; labels are derived from `ret_1h` via a threshold of `0.0`).

---

## 5. Model Configurations

### Regression Model (ret_1h)

- **Location**: `artifacts/models/xgb_ret1h_v1/xgb_ret1h_model.json`
- **Type**: `xgboost.XGBRegressor`
- **Objective**: `reg:squarederror`
- **Hyperparameters** (mirroring `train_baseline_model.py`):
  - `n_estimators = 500`
  - `max_depth = 6`
  - `learning_rate = 0.05`
  - `subsample = 0.8`
  - `colsample_bytree = 0.8`
  - `random_state = 42`
  - `n_jobs = -1`

### Direction Model (Up/Down)

- **Location**: `artifacts/models/xgb_dir1h_v1/xgb_dir1h_model.json`
- **Type**: `xgboost.XGBClassifier`
- **Objective**: `binary:logistic`
- **Hyperparameters** (mirroring `train_direction_model.py`):
  - `n_estimators = 400`
  - `max_depth = 5`
  - `learning_rate = 0.05`
  - `subsample = 0.8`
  - `colsample_bytree = 0.8`
  - `random_state = 42`
  - `n_jobs = -1`
  - `eval_metric = "logloss"`

Training scripts:

- Regression: `src/scripts/train_baseline_model.py`
- Direction: `src/scripts/train_direction_model.py`

Both use the NPZ datasets built from the curated table and respect the split logic above.

---

## 6. Threshold Search & Trading Logic

### Trading Strategy Definitions

For each 1h bar in the evaluation set:

- Let:
  - $\hat{r}_t$ be the predicted 1h log return from the regression model.
  - $\hat{p}^{\uparrow}_t$ be the predicted probability that `ret_1h > 0` from the direction model.
  - $r_t$ be the realized log return `ret_1h`.

Two strategies are defined:

1. **Ensemble Strategy (thresholded)**:
   - **Signal**:
     - Go long if:
       - $\hat{p}^{\uparrow}_t \ge p_{\text{up,min}}$ **and**
       - $\hat{r}_t \ge r_{\text{min}}$.
   - Realized return for bar $t$:
     - $r_t \cdot \mathbf{1}\{\text{signal}_t = 1\}$

2. **Direction-Only Baseline**:
   - **Signal**:
     - Go long if $\hat{p}^{\uparrow}_t \ge 0.5$.
   - Realized return for bar $t$:
     - $r_t \cdot \mathbf{1}\{\hat{p}^{\uparrow}_t \ge 0.5\}$

### Threshold Search (`src/scripts/search_ensemble_thresholds.py`)

- Performs a grid search over `(p_up_min, ret_min)` using **validation** data:
  - Default grids (v1) are centered around the v1 default thresholds defined in `src/config_trading.py`:
    - `DEFAULT_P_UP_MIN = 0.45`
    - `DEFAULT_RET_MIN = 0.0`
  - CLI options:
    - `--p-up-min-list` / `--ret-min-list` to specify grids explicitly.
    - **Robustness**: `--p-up-grid` and `--ret-min-grid` override both the defaults and the `*-list` options.
- For each pair:
  - Computes validation ensemble signals and metrics:
    - `n_trades`, `hit_rate`, `avg_ret_per_trade`, `cum_ret`.
  - Enforces a minimum validation trade count (preferred and fallback thresholds).
  - Selects the pair with **maximum validation cumulative return** among those that satisfy the trade-count constraint.
- The chosen thresholds are then evaluated on the **test** set and summary metrics are printed.

Current v1 default thresholds (from recent grid searches and robustness checks):

- `p_up_min = 0.45`
- `ret_min = 0.00000`

#### Advanced (v2): Risk-aware Threshold Search

- The grid search CLI now supports alternative objectives and constraints:
  - `--objective sharpe_like` maximizes cumulative return scaled by return volatility for active trades.
  - `--objective cumret_with_dd_constraint` maximizes cumulative return while discarding candidates that breach `--max-dd` (log drawdown) if provided.
  - `--min-trades` enforces a hard minimum validation trade count across all objectives.
  - `--max-dd` (with the drawdown-aware objective) caps acceptable validation drawdowns (e.g., `-0.10` for ≤10% log drawdown).
- Example (v2-style) command exploring drawdown-constrained thresholds:

```bash
python -m src.scripts.search_ensemble_thresholds \
  --dataset-path artifacts/datasets/btc_features_1h_splits.npz \
  --reg-model-dir artifacts/models/xgb_ret1h_v1 \
  --dir-model-dir artifacts/models/xgb_dir1h_v1 \
  --objective cumret_with_dd_constraint \
  --max-dd -0.10 \
  --min-trades 300
```

#### v2 (multi-horizon): 4h targets and models

- Multi-horizon target helper now produces `ret_4h` / `dir_4h` alongside the existing 1h labels using the same curated feature set and split boundaries.
- XGBoost baselines for the 4h horizon live under `artifacts/models/xgb_ret4h_v1/` and `artifacts/models/xgb_dir4h_v1/`, trained from the shared multi-horizon dataset (`btc_features_multi_horizon_splits.npz`).
- Example training commands:

```bash
python -m src.scripts.build_training_dataset_multi_horizon
python -m src.scripts.train_xgb_ret4h_v1
python -m src.scripts.train_xgb_dir4h_v1
```

- **4h backtest (v2 extension)**
  - Script: `src/scripts/backtest_signals_4h.py`
  - Output: `artifacts/analysis/backtest_signals_4h_v1/backtest_signals_4h.csv`

```bash
python -m src.scripts.backtest_signals_4h \
  --dataset-path artifacts/datasets/btc_features_multi_horizon_splits.npz \
  --reg-model-dir artifacts/models/xgb_ret4h_v1 \
  --dir-model-dir artifacts/models/xgb_dir4h_v1 \
  --p-up-min 0.55 \
  --ret-min 0.00000 \
  --fee-bps 2.0 \
  --slippage-bps 1.0 \
  --use-test-split \
  --output-dir artifacts/analysis/backtest_signals_4h_v1
```

- **4h historical paper trading (v2 extension)**
  - Script: `src/scripts/paper_trade_loop_4h.py`
  - Output: `artifacts/analysis/paper_trade_4h_v1/paper_trade_4h.csv`

```bash
python -m src.scripts.paper_trade_loop_4h \
  --dataset-path artifacts/datasets/btc_features_multi_horizon_splits.npz \
  --reg-model-dir artifacts/models/xgb_ret4h_v1 \
  --dir-model-dir artifacts/models/xgb_dir4h_v1 \
  --p-up-min 0.55 \
  --ret-min 0.00000 \
  --fee-bps 2.0 \
  --slippage-bps 1.0 \
  --use-test-split \
  --output-dir artifacts/analysis/paper_trade_4h_v1
```

Both scripts reuse the shared signal helpers so v1 (1h) behavior stays untouched; the 4h workflows are optional add-ons when the multi-horizon dataset and models are available.

- **1h + 4h confirmation backtest (v2 experiment)**
  - Script: `src/scripts/backtest_signals_1h4h_confirm.py`
  - Output: `artifacts/analysis/backtest_signals_1h4h_confirm_v1/backtest_signals_1h4h.csv`

```bash
python -m src.scripts.backtest_signals_1h4h_confirm \
  --bt1h-path artifacts/analysis/backtest_signals_v1/backtest_signals.csv \
  --bt4h-path artifacts/analysis/backtest_signals_4h_v1/backtest_signals_4h.csv \
  --p-up-min-4h 0.55 \
  --fee-bps 2.0 \
  --slippage-bps 1.0 \
  --output-dir artifacts/analysis/backtest_signals_1h4h_confirm_v1
```

This optional analysis keeps the original 1h ensemble logic but only enters trades when the 4h view is also bullish (based on `p_up_4h`), letting you quantify the trade-off between selectivity and performance before promoting the rule to realtime use.

- **Realtime logging (v2 experiment: 1h + 4h confirmation)**
  - `src/scripts/run_signal_realtime.py` and `src/scripts/run_signal_realtime_from_binance.py` expose optional 4h flags: `--dataset-path-4h`, `--reg-model-dir-4h`, and `--dir-model-dir-4h`. Supplying all three (plus the existing `--p-up-min-4h-confirm`) enables realtime 4h inference so `p_up_4h`, `ret_pred_4h`, and `signal_1h4h_confirm` populate in the live log.
  - Definition: `signal_1h4h_confirm = 1` iff `signal_ensemble == 1` **and** `p_up_4h >= 0.55`, matching `src/scripts/backtest_signals_1h4h_confirm.py`.
  - Example (BigQuery-curated path):

```bash
python -m src.scripts.run_signal_realtime \
  --dataset-path artifacts/datasets/btc_features_1h_splits.npz \
  --reg-model-dir artifacts/models/xgb_ret1h_v1 \
  --dir-model-dir artifacts/models/xgb_dir1h_v1 \
  --dataset-path-4h artifacts/datasets/btc_features_multi_horizon_splits.npz \
  --reg-model-dir-4h artifacts/models/xgb_ret4h_v1 \
  --dir-model-dir-4h artifacts/models/xgb_dir4h_v1 \
  --log-path artifacts/live/paper_trade_realtime.csv \
  --p-up-min 0.45 \
  --ret-min 0.0 \
  --p-up-min-4h-confirm 0.55
```

  - Example (Binance fallback path):

```bash
python -m src.scripts.run_signal_realtime_from_binance \
  --symbol BTCUSDT \
  --interval 1h \
  --n-bars 500 \
  --dataset-path artifacts/datasets/btc_features_1h_splits.npz \
  --reg-model-dir artifacts/models/xgb_ret1h_v1 \
  --dir-model-dir artifacts/models/xgb_dir1h_v1 \
  --dataset-path-4h artifacts/datasets/btc_features_multi_horizon_splits.npz \
  --reg-model-dir-4h artifacts/models/xgb_ret4h_v1 \
  --dir-model-dir-4h artifacts/models/xgb_dir4h_v1 \
  --log-path artifacts/live/paper_trade_realtime.csv \
  --p-up-min 0.45 \
  --ret-min 0.0 \
  --p-up-min-4h-confirm 0.55
```

  - The combined column is surfaced for decision-support in realtime runs but does **not** modify the existing v1 trading rules, metrics, or backtest outputs.

---

## 7. Evaluation & Walk-Forward

### Single-Split Test Metrics (Post-Leak Fix)

Using the standard train/val/test split (last 15% as test), approximate metrics are:

- **Regression (ret_1h)**:
  - Test RMSE: `0.00431`
  - Test MAE: `0.00305`
- **Direction (1{ret_1h > 0})**:
  - Test accuracy: `0.657`
  - Test F1: `0.637`

Ensemble vs direction-only (test) with **v1 default thresholds** `p_up_min = 0.45`, `ret_min = 0.0`:

- **Ensemble (gross of costs)**:
  - `n_trades = 721`
  - `hit_rate = 0.717`
  - `cum_ret (log-sum) = 1.7142`
- **Direction-only baseline (gross of costs)**:
  - `n_trades = 764`
  - `hit_rate = 0.644`
  - `cum_ret (log-sum) = 1.3466`

With **fees/slippage applied** (`fee_bps = 2.0`, `slippage_bps = 1.0`):

- **Ensemble (net of costs)**:
  - `n_trades = 721`
  - `hit_rate = 0.675`
  - `cum_ret_net (log-sum) = 1.4979`
- **Direction-only baseline (net of costs)**:
  - `n_trades = 764`
  - `hit_rate = 0.607`
  - `cum_ret_net (log-sum) = 1.1174`

### Walk-Forward Evaluation (`src/scripts/walk_forward_eval.py`)

- Reconstructs the full time series from the regression NPZ splits.
- Defines several non-overlapping test windows near the **end** of the series (default: 3).
- For each window:
  - Trains new regression and direction models on all prior data.
  - Uses an internal train/validation split of the pre-window data.
  - Reports per-window metrics:
    - Regression: RMSE, MAE.
    - Direction: accuracy, precision, recall, F1.
    - Trading (ensemble vs direction-only):
      - `n_trades`, `hit_rate`, `avg_ret_trade`, `cum_ret`, `max_drawdown`, `sharpe_like`.

Usage example (gross + net metrics):

```bash
python -m src.scripts.walk_forward_eval \
  --dataset-path artifacts/datasets/btc_features_1h_splits.npz \
  --n-folds 3 \
  --p-up-min 0.50 \
  --ret-min 0.00000
```

**Summary of v1 walk-forward (3 folds, ensemble vs direction-only, gross of costs):**

| Fold | Window (start_idx, end_idx) | Ens n_trades | Ens hit_rate | Ens cum_ret | Dir n_trades | Dir hit_rate | Dir cum_ret |
|------|-----------------------------|--------------|--------------|------------:|--------------|--------------|------------:|
| 0    | (2726, 5450)                | 1786         | 0.610        | 2.1826      | 2009         | 0.569        | 1.9409      |
| 1    | (5450, 8174)                | 1510         | 0.562        | 1.0684      | 1666         | 0.552        | 1.1611      |
| 2    | (8174, 10898)               | 766          | 0.744        | 2.0322      | 847          | 0.679        | 1.7407      |

### Equity Curve Evaluation (`src/scripts/eval_equity_curves.py`)

- Loads the regression NPZ dataset and both trained models.
- Uses the **test** split only.
- Computes ensemble and direction-only signals and returns.
- Outputs summary metrics and optionally writes per-bar equity curves to CSV.

Usage example:

```bash
python -m src.scripts.eval_equity_curves \
  --dataset-path artifacts/datasets/btc_features_1h_splits.npz \
  --reg-model-dir artifacts/models/xgb_ret1h_v1 \
  --dir-model-dir artifacts/models/xgb_dir1h_v1 \
  --p-up-min 0.45 \
  --ret-min 0.00000 \
  --fee-bps 2.0 \
  --slippage-bps 1.0 \
  --output-dir artifacts/analysis/equity_v1_fees
```

---

## 8. Key Results
 
- **Overall (gross)**:
  - On the held-out test set, the ensemble executes `721` trades with hit rate `0.717` and cumulative log return `1.7142`, versus the direction-only baseline’s `764` trades, hit rate `0.644`, and cumulative log return `1.3466`.
- **Overall (net of simple fees/slippage)**:
  - With `fee_bps = 2.0` and `slippage_bps = 1.0`, the ensemble’s net cumulative log return is `1.4979` (hit rate `0.675`), while the direction-only baseline’s net cumulative log return is `1.1174` (hit rate `0.607`).
- **Walk-forward**:
  - Across 3 non-overlapping walk-forward windows, the ensemble consistently matches or exceeds the direction-only baseline in cumulative return; in folds 0 and 2 it materially outperforms, while in fold 1 performance is comparable.
- **Risk profile**:
  - On the test split, the ensemble’s gross max drawdown is `-0.0796` (net: `-0.0880`) with Sharpe-like statistic `0.517` (net: `0.452`), compared to the baseline’s gross max drawdown of `-0.0330` (net: `-0.0482`) and Sharpe-like `0.374` (net: `0.310`).

---

## 9. Signal Scripts & Live/Paper-Trading Usage

Several scripts reuse the shared logic in `src/trading/signals.py` (feature construction, scaling, and thresholds) to bridge from backtests to historical and live-like trading:

- **Shared helper**: `src/trading/signals.py`
  - Provides `PreparedData`, `prepare_data_for_signals`, `compute_signal_for_index`, `load_models`, etc.
  - Ensures that all downstream scripts use the same feature set, feature ordering, scaler reconstruction, and threshold conventions as the v1 models.

### 9.1 Backtest signals on NPZ splits

Script: `src/scripts/backtest_signals.py`

- Purpose:
  - Backtest the ensemble strategy vs the direction-only baseline over a chosen range (e.g., the held-out test split).
  - Reconstructs realized `ret_1h` from the NPZ splits and applies the shared signal logic bar-by-bar.
- Typical usage (v1 test split with fees/slippage, writing per-bar log and summary metrics):

```bash
python -m src.scripts.backtest_signals \
  --dataset-path artifacts/datasets/btc_features_1h_splits.npz \
  --reg-model-dir artifacts/models/xgb_ret1h_v1 \
  --dir-model-dir artifacts/models/xgb_dir1h_v1 \
  --p-up-min 0.45 \
  --ret-min 0.00000 \
  --fee-bps 2.0 \
  --slippage-bps 1.0 \
  --use-test-split \
  --output-dir artifacts/analysis/backtest_signals_v1
```

This script produces a CSV log at `artifacts/analysis/backtest_signals_v1/backtest_signals.csv` and prints summary metrics that match those from `eval_equity_curves.py` when configured identically.

### 9.2 Historical paper-trading loop (position-aware)

Script: `src/scripts/paper_trade_loop.py`

- Purpose:
  - Simulate a simple, position-aware long-or-flat paper-trading strategy over a historical range (often the test split), using the ensemble signal.
  - Models entries/exits and per-trade PnL with the same fee/slippage assumptions as the backtests.
- Typical usage (v1, test split):

```bash
python -m src.scripts.paper_trade_loop \
  --dataset-path artifacts/datasets/btc_features_1h_splits.npz \
  --reg-model-dir artifacts/models/xgb_ret1h_v1 \
  --dir-model-dir artifacts/models/xgb_dir1h_v1 \
  --p-up-min 0.45 \
  --ret-min 0.00000 \
  --fee-bps 2.0 \
  --slippage-bps 1.0 \
  --use-test-split \
  --output-dir artifacts/analysis/paper_trade_v1
```

This writes a per-bar log to `artifacts/analysis/paper_trade_v1/paper_trade.csv` with columns such as `ts`, `ret_1h`, `p_up`, `ret_pred`, `signal_ensemble`, `position`, `ret_net`, and `equity`. On the v1 test split, the ensemble paper-trading loop yields roughly:

- `n_trades (entries) ≈ 339`
- `hit_rate ≈ 0.805`
- `cum_ret (log-sum) ≈ 1.51`
- `max_drawdown (log) ≈ -0.085`

### 9.3 Realtime-like signal logger

Script: `src/scripts/run_signal_realtime.py`

- Purpose:
  - Generate a single live-like ensemble/direction signal for the latest completed bar and append it to a CSV log, suitable for hourly cron/scheduler usage.
  - Uses the same `prepare_data_for_signals` and `compute_signal_for_index` helpers, so it shares features, scaling, and thresholds with v1.
- Typical usage (single run, intended to be scheduled hourly):

```bash
python -m src.scripts.run_signal_realtime \
  --reg-model-dir artifacts/models/xgb_ret1h_v1 \
  --dir-model-dir artifacts/models/xgb_dir1h_v1 \
  --log-path artifacts/live/paper_trade_realtime.csv
```

Behavior:

- On first run, creates `artifacts/live/paper_trade_realtime.csv` with header columns:
  - `ts`, `p_up`, `ret_pred`, `signal_ensemble`, `signal_dir_only`, `created_at`, `notes`.
- On subsequent runs:
  - Loads the last logged `ts` from the CSV.
  - If the latest available bar has the **same** `ts`, it prints a clear skip message and does **not** append a new row.
  - If a new bar is available, it appends a new row with the latest signal and a `created_at` timestamp (UTC).

### 9.4 How to read the logs

For the main CSV outputs produced by the v1 scripts:

- `backtest_signals.csv` (from `backtest_signals.py`):
  - Typical columns:
    - `ts`: Timestamp for the bar.
    - `ret_1h`: Realized 1h log return.
    - `p_up`: Direction model’s P(ret_1h > 0).
    - `ret_pred`: Regression model’s predicted 1h log return.
    - `signal_ensemble`: 1 if ensemble conditions are met, else 0.
    - `signal_dir_only`: 1 if direction-only P(up) >= 0.5, else 0.
    - `ret_net_ens`, `ret_net_dir`: Net (after-cost) log return per bar for ensemble and direction-only strategies.
    - `equity_ens`, `equity_dir`: Cumulative equity (exp of cumulative log return) per bar.
  - Simple checks:
    - Plot `equity_ens` and `equity_dir` over time to compare strategies.
    - Check that `ret_net_ens` is 0 on bars with `signal_ensemble = 0` (flat regime, apart from entry/exit costs).

- `paper_trade.csv` (from `paper_trade_loop.py`):
  - Typical columns:
    - `ts`: Timestamp for each bar in the simulated period.
    - `ret_1h`: Realized 1h log return.
    - `p_up`: Direction model’s predicted P(up).
    - `ret_pred`: Regression model’s predicted 1h log return.
    - `signal_ensemble`: Ensemble signal (0/1) for that bar.
    - `position`: Actual position held during the bar (0 = flat, 1 = long); matches `signal_ensemble` for that bar.
    - `ret_net`: Net log return for that bar, including entry/exit costs when position changes.
    - `equity`: Cumulative equity (starting from 1.0) computed as `exp(cumulative log net returns)`.
  - Simple checks:
    - Confirm that `position` only changes when `signal_ensemble` flips between 0 and 1.
    - Sum of `ret_net` over the period should equal `ln(equity[-1])`.
    - Plot `equity` over time to visualize the paper-trade equity curve and compare it to the backtest `equity_ens`.

- `paper_trade_realtime.csv` (from `run_signal_realtime.py`):
  - Columns:
    - `ts`: Timestamp of the bar for which the signal was generated.
    - `p_up`: Direction model’s P(up) at that bar.
    - `ret_pred`: Regression model’s predicted 1h log return.
    - `signal_ensemble`: Ensemble signal (0/1) based on current thresholds.
    - `signal_dir_only`: Direction-only signal (0/1, based on P(up) >= 0.5).
    - `created_at`: UTC timestamp when the signal row was logged.
    - `notes`: Freeform notes (typically empty in v1).
  - Simple checks:
    - Verify that `ts` is strictly increasing (at most one row per bar).
    - If the script is run hourly, ensure there are no duplicate `ts` values; the script should log a “skipping append” message if `ts` is unchanged.

---

## 10. Known Limitations & Next Steps

### Known Limitations

- **Transaction costs & slippage**: Only a simple per-trade bps model is applied; real-world costs depend on venue, liquidity, order type, and position sizing.
- **Only long positions**: No explicit shorting or neutral regimes beyond "no position".
- **Hyperparameters**: Models use hand-chosen hyperparameters, not the result of systematic tuning.
- **Futures features**: Futures-related features (e.g., `open_interest`, `funding_rate`) currently show low importance in feature importance analyses.
- **Single-horizon label**: Focus is only on 1h returns; other horizons are not explored.

### Next Steps

- Incorporate realistic transaction cost and slippage assumptions into evaluation.
- Extend threshold search to incorporate drawdown/volatility constraints, not just cumulative return.
- Revisit the futures feature engineering to try to extract more signal.
- Expand walk-forward evaluation (more folds, different window sizes, rolling refits).
- Add monitoring/alerting for live deployment (e.g., hit-rate drift, return distribution shifts).

---

## 11. Integrity & Leakage Checklist

- **No forward-looking targets as features**:
  - `ret_fwd_3h` is explicitly excluded from `X` in `make_features_and_target`.
  - Any future-looking columns must be addressed at the SQL/curation layer; Python preprocessing only uses non-target, non-forward features.
- **Chronological splits**:
  - All train/val/test splits (including walk-forward windows) respect time ordering.
- **Scaling**:
  - For the main datasets, `StandardScaler` is fit on train only and applied to validation/test.
  - Walk-forward evaluation trains models using only pre-window data, mimicking deployment.
- **Evaluation separation**:
  - Validation and test sets are never used for model fitting.
  - Walk-forward windows are strictly later than the data used to train the models evaluated on them.

This document describes **experiment version v1** for the 2024-10-01 to 2025-12-10 BTCUSDT 1h dataset. Future experiment versions (e.g., `experiment_2024-10_to-2025-12_v2.md`) should document any changes to data, features, models, thresholds, or evaluation methodology.

---

## 12. Optuna Hyperparameter Search Workflow

- **Script**: `src/scripts/search_xgb_optuna.py` centralizes Optuna tuning for the 1h regression (`ret_1h`) and direction models built from the curated dataset.
- **Key options**:
  - `--mode {reg|dir}` toggles between regression RMSE minimization and direction logloss minimization.
  - `--n-trials` (default `50`) and `--timeout` control the Optuna budget; use higher budgets for production sweeps.
  - `--storage` and `--study-name` enable SQLite/Postgres-backed studies so experiments can resume or aggregate results.
  - `--output-dir` captures artifacts: `best_model.json`, `best_summary.json`, and a legacy `summary.json` mirror for downstream tooling.
- **Workflow**:
  1. Loads features via `prepare_data_for_signals`, sorts chronologically, and applies the standard 70/15/15 split with a `StandardScaler` fit strictly on the training slice.
  2. Runs an Optuna study that samples depth, learning rate, subsampling, regularization, and (for direction) `scale_pos_weight`. Each trial trains on the train slice with early stopping on validation.
  3. Retrains the winning configuration on train+validation, scores on the held-out test slice, and persists metrics alongside model weights.
- **Example commands** (light 10-trial sweeps; increase `--n-trials` for thorough searches):

```bash
python -m src.scripts.search_xgb_optuna \
  --dataset-path artifacts/datasets/btc_features_1h_splits.npz \
  --mode reg \
  --n-trials 10 \
  --output-dir artifacts/analysis/optuna_reg_v1

python -m src.scripts.search_xgb_optuna \
  --dataset-path artifacts/datasets/btc_features_1h_splits.npz \
  --mode dir \
  --n-trials 10 \
  --output-dir artifacts/analysis/optuna_dir_v1
```

- **Outputs**: Each run prints the best trial summary and writes model weights plus validation/test metrics to the chosen output directory. Review `best_summary.json` to compare Optuna-tuned configurations against baseline hyperparameters before promoting them to backtests, realtime scripts, or artifact storage.

### Optuna v1 threshold search (Dec-2025 refresh)

- **Models used**: `artifacts/models/xgb_ret1h_optuna` + `artifacts/models/xgb_dir1h_optuna`, trained with the Optuna-selected hyperparameters captured in their respective `best_params.json` files and retrained summaries.
- **Validation sweep**: `python -m src.scripts.search_ensemble_thresholds --dataset-path artifacts/datasets/btc_features_1h_splits.npz --reg-model-dir artifacts/models/xgb_ret1h_optuna --dir-model-dir artifacts/models/xgb_dir1h_optuna --p-up-min-grid 0.40 0.45 0.50 0.55 --ret-min-grid -0.001 0.000 0.001 0.002 --fee-bps 2.0 --slippage-bps 1.0 --output-dir artifacts/analysis/threshold_search_optuna_v1`
  - Best combo on validation (net of 2 bps fee + 1 bps slippage): `p_up_min = 0.50`, `ret_min = -0.001`, delivering `n_trades = 810`, hit rate `0.528`, cum log return `0.425`, max drawdown `-0.047`.
- **Test backtest (net)**: `python -m src.scripts.backtest_signals --dataset-path artifacts/datasets/btc_features_1h_splits.npz --reg-model-dir artifacts/models/xgb_ret1h_optuna --dir-model-dir artifacts/models/xgb_dir1h_optuna --p-up-min 0.5 --ret-min -0.001 --fee-bps 2.0 --slippage-bps 1.0 --use-test-split --output-dir artifacts/analysis/backtest_signals_v1_optuna_thresholded`
  - Ensemble net metrics: `n_trades = 1,115`, hit rate `0.563`, avg ret/trade `0.00099`, cumulative log return `1.1011`, max drawdown `-0.079`. The signal collapses to the direction-only baseline under this threshold pair, matching its net results and improving over the earlier Optuna default thresholds (w/ `p_up_min = 0.45`, `ret_min = 0.0`) which posted `0.8977` net log return.
- **Artifacts**: threshold search outputs stored under `artifacts/analysis/threshold_search_optuna_v1/` (best_config + summary) and the aligned backtest log in `artifacts/analysis/backtest_signals_v1_optuna_thresholded/`.
