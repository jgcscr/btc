# Experiment: BTCUSDT 1h Forecasting & Trading (2024-10-01 to 2025-12-10) â€“ v1

## 1. Data Window & Coverage

- **Instrument**: BTCUSDT (Binance, spot and futures).
- **Interval**: 1h bars.
- **Curated table**: `jc-financial-466902.btc_forecast_curated.btc_features_1h`
- **Coverage (ts column)**:
  - `min_ts`: `2024-10-01 00:59:59`
  - `max_ts`: `2025-12-10 23:59:59`
  - `n_rows`: `~10,899` (1h bars; exact count may vary slightly if filters change)

Raw tables used to build the curated table:

- `jc-financial-466902.btc_forecast_raw.spot_klines`
- `jc-financial-466902.btc_forecast_raw.futures_metrics`

Both raw tables were fully backfilled over the same period using Parquet files stored in:

- `gs://jc-financial-466902-btc-forecast-data/spot_klines/interval=1h/...`
- `gs://jc-financial-466902-btc-forecast-data/futures_metrics/interval=1h/...`

The curated table `btc_features_1h` was rebuilt from these raw sources and verified to match the above coverage.

---

## 2. Labels & Targets

### Primary Target

- **Name**: `ret_1h`
- **Definition**: Backward 1h log return of the BTCUSDT close price:
  - $ \text{ret_1h}_t = \ln(\text{close}_t) - \ln(\text{close}_{t-1}) $

### Direction Target

- **Name**: binary direction label
- **Definition**: $ y^{(\text{dir})}_t = \mathbf{1}\{\text{ret_1h}_t > 0\} $ with threshold `0.0`.

### Forward Return (Not Used as Feature)

- **Name**: `ret_fwd_3h`
- **Definition**: 3-hour **forward** log return (used historically as an analysis column).
- **Important**: `ret_fwd_3h` is **never** included in the feature matrix `X` for any model; it is explicitly excluded in `src/data/dataset_preparation.py`.

---

## 3. Feature Set

Features are derived from the curated table `btc_features_1h`. The Python function `make_features_and_target` in `src/data/dataset_preparation.py`:

- Sorts rows by `ts`.
- Drops rows with `NaN` in the target column.
- Uses all remaining **numeric** columns as features **except**:
  - `ts`
  - The target column (e.g., `ret_1h`)
  - `ret_fwd_3h`

Resulting feature families include (non-exhaustive):

- **Spot OHLCV**:
  - `open`, `high`, `low`, `close`
  - `volume`, `quote_volume`, `num_trades`
- **Rolling & ratio features**:
  - `ma_close_7h`, `ma_close_24h`, `ma_ratio_7_24`
  - `vol_24h` and other rolling-volume measures
- **Futures metrics** (currently low/zero importance in this experiment):
  - `fut_open`, `fut_high`, `fut_low`, `fut_close`
  - `open_interest`, `funding_rate`, and related columns

No forward-looking targets such as `ret_fwd_3h` are used as features.

---

## 4. Split Logic

Splits are implemented in `time_series_train_val_test_split` in `src/data/dataset_preparation.py`:

- **Chronological ordering**:
  - Data are sorted by `ts` before splitting.
- **Fractions**:
  - Train: `train_frac = 0.70`
  - Validation: `val_frac = 0.15`
  - Test: `test_frac = 0.15` (remainder)
- **Index-based slicing**:
  - `X_train = X[:train_end]`
  - `X_val = X[train_end:val_end]`
  - `X_test = X[val_end:]`
- **Scaling**:
  - A `StandardScaler` is **fit on `X_train` only**.
  - The fitted scaler is then applied to `X_val` and `X_test`.
- **No shuffling**:
  - There is no random shuffling; all splits respect time ordering.

This ensures:

- No label leakage from test/validation into training via scaling.
- Splits align with a realistic forward-looking evaluation.

Datasets are stored as NPZ files:

- Regression: `artifacts/datasets/btc_features_1h_splits.npz`
- Direction: `artifacts/datasets/btc_features_1h_direction_splits.npz` (for training the direction model; labels are derived from `ret_1h` via a threshold of `0.0`).

---

## 5. Model Configurations

### Regression Model (ret_1h)

- **Location**: `artifacts/models/xgb_ret1h_v1/xgb_ret1h_model.json`
- **Type**: `xgboost.XGBRegressor`
- **Objective**: `reg:squarederror`
- **Hyperparameters** (mirroring `train_baseline_model.py`):
  - `n_estimators = 500`
  - `max_depth = 6`
  - `learning_rate = 0.05`
  - `subsample = 0.8`
  - `colsample_bytree = 0.8`
  - `random_state = 42`
  - `n_jobs = -1`

### Direction Model (Up/Down)

- **Location**: `artifacts/models/xgb_dir1h_v1/xgb_dir1h_model.json`
- **Type**: `xgboost.XGBClassifier`
- **Objective**: `binary:logistic`
- **Hyperparameters** (mirroring `train_direction_model.py`):
  - `n_estimators = 400`
  - `max_depth = 5`
  - `learning_rate = 0.05`
  - `subsample = 0.8`
  - `colsample_bytree = 0.8`
  - `random_state = 42`
  - `n_jobs = -1`
  - `eval_metric = "logloss"`

Training scripts:

- Regression: `src/scripts/train_baseline_model.py`
- Direction: `src/scripts/train_direction_model.py`

Both use the NPZ datasets built from the curated table and respect the split logic above.

---

## 6. Threshold Search & Trading Logic

### Trading Strategy Definitions

For each 1h bar in the evaluation set:

- Let:
  - $\hat{r}_t$ be the predicted 1h log return from the regression model.
  - $\hat{p}^{\uparrow}_t$ be the predicted probability that `ret_1h > 0` from the direction model.
  - $r_t$ be the realized log return `ret_1h`.

Two strategies are defined:

1. **Ensemble Strategy (thresholded)**:
   - **Signal**:
     - Go long if:
       - $\hat{p}^{\uparrow}_t \ge p_{\text{up,min}}$ **and**
       - $\hat{r}_t \ge r_{\text{min}}$.
   - Realized return for bar $t$:
     - $r_t \cdot \mathbf{1}\{\text{signal}_t = 1\}$

2. **Direction-Only Baseline**:
   - **Signal**:
     - Go long if $\hat{p}^{\uparrow}_t \ge 0.5$.
   - Realized return for bar $t$:
     - $r_t \cdot \mathbf{1}\{\hat{p}^{\uparrow}_t \ge 0.5\}$

### Threshold Search (`src/scripts/search_ensemble_thresholds.py`)

- Performs a grid search over `(p_up_min, ret_min)` using **validation** data:
  - Default grids (v1) are centered around the v1 default thresholds defined in `src/config_trading.py`:
    - `DEFAULT_P_UP_MIN = 0.45`
    - `DEFAULT_RET_MIN = 0.0`
  - CLI options:
    - `--p-up-min-list` / `--ret-min-list` to specify grids explicitly.
    - **Robustness**: `--p-up-grid` and `--ret-min-grid` override both the defaults and the `*-list` options.
- For each pair:
  - Computes validation ensemble signals and metrics:
    - `n_trades`, `hit_rate`, `avg_ret_per_trade`, `cum_ret`.
  - Enforces a minimum validation trade count (preferred and fallback thresholds).
  - Selects the pair with **maximum validation cumulative return** among those that satisfy the trade-count constraint.
- The chosen thresholds are then evaluated on the **test** set and summary metrics are printed.

Current v1 default thresholds (from recent grid searches and robustness checks):

- `p_up_min = 0.45`
- `ret_min = 0.00000`

---

## 7. Evaluation & Walk-Forward

### Single-Split Test Metrics (Post-Leak Fix)

Using the standard train/val/test split (last 15% as test), approximate metrics are:

- **Regression (ret_1h)**:
  - Test RMSE: `~0.00431`
  - Test MAE: `~0.00305`
- **Direction (1{ret_1h > 0})**:
  - Test accuracy: `~0.657`
  - Test F1: `~0.637`

Ensemble vs direction-only (test) with **v1 default thresholds** `p_up_min = 0.45`, `ret_min = 0.0`:

- **Ensemble (gross of costs)**:
  - `n_trades ~ [fill from latest run]`
  - `hit_rate ~ [fill from latest run]`
  - `cum_ret (log-sum) ~ [fill from latest run]`
- **Direction-only baseline (gross of costs)**:
  - `n_trades ~ [fill from latest run]`
  - `hit_rate ~ [fill from latest run]`
  - `cum_ret (log-sum) ~ [fill from latest run]`

With **fees/slippage applied** (`fee_bps = 2.0`, `slippage_bps = 1.0`):

- **Ensemble (net of costs)**:
  - `n_trades ~ [fill from latest run]`
  - `hit_rate ~ [fill from latest run]`
  - `cum_ret_net (log-sum) ~ [fill from latest run]`
- **Direction-only baseline (net of costs)**:
  - `n_trades ~ [fill from latest run]`
  - `hit_rate ~ [fill from latest run]`
  - `cum_ret_net (log-sum) ~ [fill from latest run]`

### Walk-Forward Evaluation (`src/scripts/walk_forward_eval.py`)

- Reconstructs the full time series from the regression NPZ splits.
- Defines several non-overlapping test windows near the **end** of the series (default: 3).
- For each window:
  - Trains new regression and direction models on all prior data.
  - Uses an internal train/validation split of the pre-window data.
  - Reports per-window metrics:
    - Regression: RMSE, MAE.
    - Direction: accuracy, precision, recall, F1.
    - Trading (ensemble vs direction-only):
      - `n_trades`, `hit_rate`, `avg_ret_trade`, `cum_ret`, `max_drawdown`, `sharpe_like`.

Usage example (gross + net metrics):

```bash
python -m src.scripts.walk_forward_eval \
  --dataset-path artifacts/datasets/btc_features_1h_splits.npz \
  --n-folds 3 \
  --p-up-min 0.50 \
  --ret-min 0.00000
```

### Equity Curve Evaluation (`src/scripts/eval_equity_curves.py`)

- Loads the regression NPZ dataset and both trained models.
- Uses the **test** split only.
- Computes ensemble and direction-only signals and returns.
- Outputs summary metrics and optionally writes per-bar equity curves to CSV.

Usage example:

```bash
python -m src.scripts.eval_equity_curves \
  --dataset-path artifacts/datasets/btc_features_1h_splits.npz \
  --reg-model-dir artifacts/models/xgb_ret1h_v1 \
  --dir-model-dir artifacts/models/xgb_dir1h_v1 \
  --p-up-min 0.45 \
  --ret-min 0.00000 \
  --fee-bps 2.0 \
  --slippage-bps 1.0 \
  --output-dir artifacts/analysis/equity_v1_fees
```

---

## 8. Key Results (Placeholders)

> Fill in with numbers from the latest runs.

- **Overall (gross)**:
  - Ensemble strategy outperforms the direction-only baseline on the held-out test set in terms of cumulative return and hit rate, with fewer trades.
- **Overall (net of simple fees/slippage)**:
  - [TODO] Confirm that the ensemble remains preferable once `fee_bps` and `slippage_bps` are applied; fill in net cumulative returns from `eval_equity_curves` output.
- **Walk-forward**:
  - [TODO] Summarize per-window performance from `walk_forward_eval.py`, highlighting stability (or lack thereof) of ensemble vs baseline across folds.
- **Risk profile**:
  - [TODO] Summarize max drawdown and Sharpe-like statistics for each strategy (gross and net).

---

## 9. Known Limitations & Next Steps

### Known Limitations

- **Transaction costs & slippage**: Only a simple per-trade bps model is applied; real-world costs depend on venue, liquidity, order type, and position sizing.
- **Only long positions**: No explicit shorting or neutral regimes beyond "no position".
- **Hyperparameters**: Models use hand-chosen hyperparameters, not the result of systematic tuning.
- **Futures features**: Futures-related features (e.g., `open_interest`, `funding_rate`) currently show low importance in feature importance analyses.
- **Single-horizon label**: Focus is only on 1h returns; other horizons are not explored.

### Next Steps

- Incorporate realistic transaction cost and slippage assumptions into evaluation.
- Extend threshold search to incorporate drawdown/volatility constraints, not just cumulative return.
- Revisit the futures feature engineering to try to extract more signal.
- Expand walk-forward evaluation (more folds, different window sizes, rolling refits).
- Add monitoring/alerting for live deployment (e.g., hit-rate drift, return distribution shifts).

---

## 10. Integrity & Leakage Checklist

- **No forward-looking targets as features**:
  - `ret_fwd_3h` is explicitly excluded from `X` in `make_features_and_target`.
  - Any future-looking columns must be addressed at the SQL/curation layer; Python preprocessing only uses non-target, non-forward features.
- **Chronological splits**:
  - All train/val/test splits (including walk-forward windows) respect time ordering.
- **Scaling**:
  - For the main datasets, `StandardScaler` is fit on train only and applied to validation/test.
  - Walk-forward evaluation trains models using only pre-window data, mimicking deployment.
- **Evaluation separation**:
  - Validation and test sets are never used for model fitting.
  - Walk-forward windows are strictly later than the data used to train the models evaluated on them.

This document describes **experiment version v1** for the 2024-10-01 to 2025-12-10 BTCUSDT 1h dataset. Future experiment versions (e.g., `experiment_2024-10_to-2025-12_v2.md`) should document any changes to data, features, models, thresholds, or evaluation methodology.
